{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "430w1zf5CD5B"
      },
      "source": [
        "## Homework 1c: Large Language Model Inference\n",
        "\n",
        "Modern language models are often trained on hundreds of gigabytes of data and can't be easily replicated as a course project. In this assignment, we'll show how to use existing pre-trained transformer language models with the Python [`transformers` library](https://huggingface.co/docs/transformers/index)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rJaHQbVKB97u"
      },
      "outputs": [],
      "source": [
        "# This block handles some basic setup and data loading.  \n",
        "# You shouldn't need to edit this, but if you want to \n",
        "# import other standard python packages, that is fine.\n",
        "\n",
        "# imports\n",
        "from collections import defaultdict, Counter\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "import random\n",
        "import pdb\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchtext.legacy as torchtext\n",
        "\n",
        "# download and load the data\n",
        "text_field = torchtext.data.Field()\n",
        "datasets = torchtext.datasets.WikiText2.splits(root='.', text_field=text_field)\n",
        "train_dataset, validation_dataset, test_dataset = datasets\n",
        "\n",
        "text_field.build_vocab(train_dataset, validation_dataset, test_dataset)\n",
        "vocab = text_field.vocab\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "train_text = train_dataset.examples[0].text # a list of tokens (strings)\n",
        "validation_text = validation_dataset.examples[0].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBfwge86hzqA"
      },
      "source": [
        "### Inference with Autoregressive Models\n",
        "\n",
        "We'll start by computing word probabilities under the autoregressive [GPT-2 model](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf). To do so, we'll install the `transformers` library, which isn't natively installed on Google Colaboratory. We'll import a pre-trained `GPT2LMHeadModel` and its corresponding tokenizer, `GPT2TokenizerFast`. Note that without additional training, you can't freely mix-and-match models and their corresponding tokenizers! We aren't using the largest available models, such as [GPT-3](https://arxiv.org/abs/2005.14165), because they do not provide free inference. Larger freely available models such as [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6B) do exist though, and you should feel free to play around with them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4YSzh54mh4VP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (4.15.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: importlib-metadata in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: filelock in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (3.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (2022.1.18)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: dataclasses in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: requests in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from transformers) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: colorama in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from requests->transformers) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from requests->transformers) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from sacremoses->transformers) (1.16.0)\n",
            "Requirement already satisfied: click in c:\\users\\yangh\\anaconda3\\envs\\gluon\\lib\\site-packages (from sacremoses->transformers) (8.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers\n",
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouw5PdL-kLjk"
      },
      "source": [
        "The following code downloads model weights and can take a few minutes to run. For debugging purposes, feel free to swap out `gpt2-large` with a smaller model that downloads faster, but please submit your results using the `gpt2-large` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dhN127r9h5Ly"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(\"Running on GPU\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Running on CPU\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\").to(device)\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2-large\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnIQqtT5lKfz"
      },
      "source": [
        "We'll extract the vocabulary from the tokenizer so that we can easily see the words we're dealing with:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KrZao3FriCVW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50257/50257 [00:00<00:00, 1932977.56it/s]\n"
          ]
        }
      ],
      "source": [
        "vocab_map = {}\n",
        "vocab = tokenizer.vocab\n",
        "for token in tqdm.tqdm(vocab):\n",
        "    idx = vocab[token]\n",
        "    vocab_map[idx] = token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwLlkW7BlUv3"
      },
      "source": [
        "We can use our tokenizer to convert sentences into tensors and use `vocab_map` to see what indices of these tensors correspond to. This will show which words are broken into subwords by the GPT-2 tokenizer. Note that `<|endoftext|>` is equivalent to `<eos>` in the previous notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d7FnXT2qiukw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256,    40,  1842,   406,  2257, 10128]])\n",
            "['<|endoftext|>', 'I', 'Ġlove', 'ĠL', 'ST', 'Ms']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"<|endoftext|>I love LSTMs\"\n",
        "encodings = tokenizer(sentence, return_tensors='pt')\n",
        "print(encodings[\"input_ids\"])\n",
        "print([vocab_map[int(idx)] for idx in encodings[\"input_ids\"][0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMHp2Y6qmTlh"
      },
      "source": [
        "As we can see from the above example, rare words like \"LSTMs\" are broken into multiple subwords by the GPT-2 tokenizer. Additionally, note that the token \"Ġ\" corresponds to a blank space, so we can reconstruct word boundaries from the tokenizer outputs. Given a sentence, we'll now use GPT-2 to compute contextual word probabilities for every word. Some hints for doing this:\n",
        "\n",
        "\n",
        "* Check the documentation for the GPT2LMHeadModel here: https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2LMHeadModel\n",
        "* Begin by adding the `<|endoftext|>` token and passing the sentence into the tokenizer, as shown above\n",
        "* Compute word probabilities by taking `model(input_ids).logits`\n",
        "* Then, you'll need to `softmax` and index into the logits using `torch.gather` (the hardest part)\n",
        "* Finally, convert to word probabilities (rather than subword probabilities) using `vocab_map` and the \"Ġ\" token\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ZMN_3N3ui5_y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The florist sent the flowers was pleased.\n",
            "torch.Size([10, 50257])\n",
            "tensor([[2.4791],\n",
            "        [9.5224],\n",
            "        [3.4257],\n",
            "        [0.3617],\n",
            "        [8.1424],\n",
            "        [2.3662],\n",
            "        [1.4056],\n",
            "        [9.1306],\n",
            "        [7.2621],\n",
            "        [2.6502]], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "['<|endoftext|>', 'The', 'Ġfl', 'or', 'ist', 'Ġsent', 'Ġthe', 'Ġflowers', 'Ġwas', 'Ġpleased', '.']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('The', 2.4790921211242676),\n",
              " ('Ġflorist', 13.309798449277878),\n",
              " ('Ġsent', 8.142409324645996),\n",
              " ('Ġthe', 2.3661890029907227),\n",
              " ('Ġflowers', 1.405616044998169),\n",
              " ('Ġwas', 9.130634307861328),\n",
              " ('Ġpleased.', 9.912347078323364)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Input: sentence (a string)\n",
        "# Output: a list of (word, probability) tuples\n",
        "#         -> word (string)\n",
        "#         -> probability (float)\n",
        "def get_gpt_probs(sentence):\n",
        "    print(sentence)\n",
        "    # YOUR CODE HERE\n",
        "    words = []\n",
        "    probs = []\n",
        "    # BEGIN SOLUTION\n",
        "    added_sentence = \"<|endoftext|>\" + sentence\n",
        "    encodings = tokenizer(added_sentence, return_tensors='pt')\n",
        "    for i in encodings:\n",
        "        encodings[i] = encodings[i].cuda()\n",
        "    idx = encodings[\"input_ids\"][0].cuda()\n",
        "    #print(idx, encodings)\n",
        "    input_id = idx[:-1]\n",
        "    output_id = idx[1:]\n",
        "    logits = model(input_id).logits\n",
        "\n",
        "    #print(logits)\n",
        "    after_softmax = torch.softmax(logits, 1)\n",
        "    #print(max(after_softmax[0]))\n",
        "    print(after_softmax.size())\n",
        "    gathered_logits = -torch.log(torch.gather(after_softmax, 1, output_id.unsqueeze(1)))\n",
        "    print(gathered_logits)\n",
        "    subword = [vocab_map[int(idx)] for idx in encodings[\"input_ids\"][0]]\n",
        "    print(subword)\n",
        "    \n",
        "    subword = subword[1:]\n",
        "\n",
        "    probs.append(gathered_logits[0].item())\n",
        "    words.append(subword[0])\n",
        "\n",
        "    for i in range(1, len(subword)):\n",
        "        prob = gathered_logits[i].item()\n",
        "\n",
        "        if subword[i][0] == \"Ġ\":\n",
        "\n",
        "            probs.append(prob)\n",
        "            words.append(subword[i])\n",
        "        else:\n",
        "            probs[-1] += prob\n",
        "            words[-1] += subword[i]\n",
        "    \n",
        "    # END SOlUTION\n",
        "    return [(word, prob) for word, prob in zip(words, probs)]\n",
        "            \n",
        "get_gpt_probs(\"The florist sent the flowers was pleased.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eGxFz88u6ZbX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 50257])\n",
            "tensor([[2.4791],\n",
            "        [9.5224],\n",
            "        [3.4257],\n",
            "        [0.3617],\n",
            "        [8.1424],\n",
            "        [2.3662],\n",
            "        [1.4056],\n",
            "        [9.1306],\n",
            "        [7.2621],\n",
            "        [2.6502]], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "['<|endoftext|>', 'The', 'Ġfl', 'or', 'ist', 'Ġsent', 'Ġthe', 'Ġflowers', 'Ġwas', 'Ġpleased', '.']\n",
            "Passed\n",
            "torch.Size([5, 50257])\n",
            "tensor([[4.2261],\n",
            "        [5.0416],\n",
            "        [8.0565],\n",
            "        [6.8081],\n",
            "        [2.9924]], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "['<|endoftext|>', 'I', 'Ġlike', 'ĠL', 'ST', 'Ms']\n",
            "Passed\n"
          ]
        }
      ],
      "source": [
        "# To check that your implementation is roughly correct:\n",
        "def compare_probs(predictions, gold):\n",
        "  assert len(predictions) == len(gold)\n",
        "  for x,y in zip(predictions, gold):\n",
        "    assert np.abs(x[1]-y[1]) < 0.01\n",
        "  print(\"Passed\")\n",
        "\n",
        "predictions = get_gpt_probs(\"The florist sent the flowers was pleased.\")\n",
        "gold = [('The', 2.4790916442871094), ('Ġflorist', 13.309800148010254), ('Ġsent', 8.14240837097168), ('Ġthe', 2.3661890029907227), ('Ġflowers', 1.4056150913238525), ('Ġwas', 9.130632400512695), ('Ġpleased.', 9.912347793579102)]\n",
        "compare_probs(predictions, gold)\n",
        "\n",
        "predictions = get_gpt_probs(\"I like LSTMs\")\n",
        "gold = [('I', 4.226133823394775), ('Ġlike', 5.041623115539551), ('ĠLSTMs', 17.857036590576172)]\n",
        "compare_probs(predictions, gold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbej6x_TtA8p"
      },
      "source": [
        "We wrote some plotting code so you can visualize these probabilities for individual sentences. Note that this code might break on unusually long sentences, but we've provided a couple of examples below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QL7bX5T8i7j8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 50257])\n",
            "tensor([[2.4791],\n",
            "        [9.5224],\n",
            "        [3.4257],\n",
            "        [0.3617],\n",
            "        [8.1424],\n",
            "        [2.3662],\n",
            "        [1.4056],\n",
            "        [9.1306],\n",
            "        [7.2621],\n",
            "        [2.6502]], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "['<|endoftext|>', 'The', 'Ġfl', 'or', 'ist', 'Ġsent', 'Ġthe', 'Ġflowers', 'Ġwas', 'Ġpleased', '.']\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 50257])\n",
            "tensor([[2.4791],\n",
            "        [9.5224],\n",
            "        [3.4257],\n",
            "        [0.3617],\n",
            "        [8.1424],\n",
            "        [2.3662],\n",
            "        [1.4056],\n",
            "        [0.9438],\n",
            "        [3.3717],\n",
            "        [1.9530]], device='cuda:0', grad_fn=<NegBackward0>)\n",
            "['<|endoftext|>', 'The', 'Ġfl', 'or', 'ist', 'Ġsent', 'Ġthe', 'Ġflowers', 'Ġto', 'Ġme', '.']\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_gpt_probs(sentence):\n",
        "  words = sentence.split()\n",
        "  probs = get_gpt_probs(sentence)\n",
        "  assert len(words) == len(probs)\n",
        "  probs = np.asarray([probs[0][1]] + [prob[1] for prob in probs])\n",
        "  x = np.arange(len(probs))\n",
        "  plt.step(x, probs, where=\"pre\", color=\"black\", linestyle=\"dashed\")\n",
        "  text_x = (x[1:] + x[:-1])/2\n",
        "  text_y = probs[1:] + 0.25\n",
        "  for idx in range(len(words)):\n",
        "      plt.text(text_x[idx], text_y[idx], words[idx], ha=\"center\")\n",
        "  plt.ylim([min(probs)-1, max(probs)+1])\n",
        "  plt.xticks()\n",
        "  plt.ylabel(\"Log Likelihood (GPT-2)\")\n",
        "  plt.tick_params(\n",
        "      axis='x', \n",
        "      which='both', \n",
        "      bottom=False, \n",
        "      top=False,\n",
        "      labelbottom=False)\n",
        "  plt.show()\n",
        "\n",
        "plot_gpt_probs(\"The florist sent the flowers was pleased.\")\n",
        "plot_gpt_probs(\"The florist sent the flowers to me.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKwBKt3VtSCy"
      },
      "source": [
        "The first sentence above is an example of a [garden-path sentence](https://en.wikipedia.org/wiki/Garden-path_sentence). Even though it's a fairly common word, \"was\" is assigned low probability because it's unlikely in the context; other words like \"florist\" and \"pleased\" are also low probability, but they're rarer across all contexts they appear in (i.e., lower unigram probability). The second sentence shows a non-garden-path continuation with much higher probability.\n",
        "\n",
        "One downside of transformer language models is that they have a fixed length, so [computing perplexity can be expensive](https://huggingface.co/transformers/v3.2.0/perplexity.html). Although using a sliding window is the most principled way to compute perplexity with GPT-2, [striding can also provide good results with faster inference](https://arxiv.org/pdf/2012.15832.pdf). Next, we'll modify our existing function to handle longer sequences. Our model has an effective context length of 1024 tokens, and we'll use a stride of 512. This means that every token will be predicted with at least 512 tokens in the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZKeL7Jtoi9VX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context length: 1024\n"
          ]
        }
      ],
      "source": [
        "stride = 512\n",
        "print(\"Context length: {}\".format(model.config.n_positions))\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WsZDbz-6yqJE"
      },
      "outputs": [],
      "source": [
        "def get_gpt_probs(document, stride=512):\n",
        "    # YOUR CODE HERE\n",
        "    a = torch.cuda.memory_allocated(0)\n",
        "    print(a)\n",
        "    encodings = tokenizer(document, return_tensors='pt')\n",
        "    print(encodings)\n",
        "    encod_ids = encodings[\"input_ids\"][0]\n",
        "    a = torch.cuda.memory_allocated(0)\n",
        "    print(a)\n",
        "    #print(encodings)\n",
        "    words = [\"\"]\n",
        "    probs = [0]\n",
        "\n",
        "    # BEGIN SOLUTION\n",
        "\n",
        "    doc_len = len(encodings[\"input_ids\"][0])\n",
        "    encode_len = 1024\n",
        "    stride = 512\n",
        "    num_sentence = math.ceil((doc_len - encode_len)/stride) + 1\n",
        "    print(num_sentence)\n",
        "\n",
        "    sentences = []\n",
        "    \n",
        "    for i in range(num_sentence):\n",
        "        print(i)\n",
        "        start_idx = i*stride\n",
        "        end_idx = min(start_idx + encode_len, doc_len - 1)\n",
        "        idx = encod_ids[start_idx: end_idx].cuda()\n",
        "        \n",
        "        print(len(idx))\n",
        "        \n",
        "        # idx = encod[\"input_ids\"][0].cuda()\n",
        "        #print(idx, encod)\n",
        "        input_id = idx[:-1]\n",
        "        if i == 0:\n",
        "            output_id = idx[1:]\n",
        "        else:\n",
        "            output_id = idx[min(512, len(idx)):]\n",
        "        logits = model(input_id).logits\n",
        "        \n",
        "        #print(logits)\n",
        "        after_softmax = torch.softmax(logits, 1)\n",
        "        #print(max(after_softmax[0]))\n",
        "        #print(after_softmax.size())\n",
        "        gathered_logits = -torch.log(torch.gather(after_softmax, 1, output_id.unsqueeze(1)))\n",
        "        #print(gathered_logits)\n",
        "        subword = [vocab_map[int(idx)] for idx in output_id]\n",
        "    #print(subword)\n",
        "\n",
        "        for i in range(len(subword)):\n",
        "            prob = gathered_logits[i].item()\n",
        "\n",
        "            if subword[i][0] == \"Ġ\":\n",
        "\n",
        "                probs.append(prob)\n",
        "                words.append(subword[i])\n",
        "            else:\n",
        "                probs[-1] += prob\n",
        "                words[-1] += subword[i]\n",
        "    \n",
        "    \n",
        "    # END SOlUTION\n",
        "    result = [(word, prob) for word, prob in zip(words, probs)]\n",
        "    print(result)\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4SHhy4N5ZfT"
      },
      "source": [
        "We'll now compute the probabilities of every word in *Pride and Prejudice* using GPT-2. Note that this will take a very long time to run with a small stride, so you're encouraged to get the implementation of striding correct. You'll submit the output probabilities as `word_probs.npy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HXbHUzV50Ihn"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4699031040\n",
            "{'input_ids': tensor([[171, 119, 123,  ...,  13, 628, 198]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
            "4699031040\n",
            "454\n",
            "0\n",
            "76175872\n",
            "1024\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 4.38 GiB already allocated; 19.81 MiB free; 4.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-35f61d435fb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pride.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_gpt_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-12-1485e1512c91>\u001b[0m in \u001b[0;36mget_gpt_probs\u001b[1;34m(document, stride)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0moutput_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m#print(logits)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\yangh\\Anaconda3\\envs\\gluon\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\yangh\\Anaconda3\\envs\\gluon\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m         )\n\u001b[0;32m   1059\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\yangh\\Anaconda3\\envs\\gluon\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\yangh\\Anaconda3\\envs\\gluon\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwte\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         \u001b[0mposition_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\yangh\\Anaconda3\\envs\\gluon\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\yangh\\Anaconda3\\envs\\gluon\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    158\u001b[0m         return F.embedding(\n\u001b[0;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\yangh\\Anaconda3\\envs\\gluon\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2042\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 6.00 GiB total capacity; 4.38 GiB already allocated; 19.81 MiB free; 4.45 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "!wget https://cal-cs288.github.io/sp22/project_files/hw1/pride.txt\n",
        "with open(\"pride.txt\", \"r\", encoding=\"utf-8\") as infile:\n",
        "  text = infile.read()\n",
        "output = get_gpt_probs(text, stride=512)\n",
        "probs = np.asarray([val[1] for val in output])\n",
        "print(probs)\n",
        "np.save(\"word_probs.npy\", probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VibM4aB54IK"
      },
      "source": [
        "### Prompting with Language Models\n",
        "\n",
        "Language models can be coerced into performing a variety of different tasks via *prompting*, as shown in the [GPT-3 paper](https://arxiv.org/abs/2005.14165). At a high level, prompting involves putting a few training examples into the context of a model and then using next word prediction to predict labels. In this assignment, we'll use prompting and the GPT-2 Large model on the sentiment task SST-2. But first, we'll download the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lc80b6BX1iR0"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"glue\", \"sst2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtmhDp_PT8EC"
      },
      "source": [
        "Now, it's time to write a prompt for sentiment prediction. Here's an example what a prompt might look like for the task of machine translation:\n",
        "\n",
        "\n",
        "```\n",
        "The French \"Le Tea Party est atterré.\" in English is \"The tea party is aghast\"\n",
        "The French \"Cela est vraiment indispensable pour notre nation.\" in English is \"This really is a must for our nation.\"\n",
        "The French \"Il va y avoir du changement dans la façon dont nous payons ces taxes.\" in English is \"There is going to be a change in how we pay these taxes.\"\n",
        "The French \"La technologie est là pour le faire.\" in English is\n",
        "```\n",
        "The model would then predict the next tokens, hopefully resulting in an English translation of the final sentence. Note that these examples are all taken from the `wmt14` translation dataset. In our case, however, we'll be predicting sentiment, which is represented by a binary value in the Stanford Sentiment Treebank. To convert next-word predictions into a binary decision, we'll compute the probability of two words (e.g., \"yes\" vs. \"no\") and then choose our label based on whichever one has the highest probability. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byloT-Sz8mQF"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(sentence):\n",
        "  # YOUR CODE HERE\n",
        "  # - Write a prompt using 3-5 example sentences\n",
        "  # - Append the current example to the prompt, with a template\n",
        "  # - Compare probabilities of possible next tokens to get a predicted label\n",
        "  # - Warning: DO NOT TRAIN OR FINE-TUNE A MODEL FOR THIS ASSIGNMENT\n",
        "  # BEGIN SOLUTION\n",
        "\n",
        "  # END SOLUTION\n",
        "\n",
        "num_correct = 0\n",
        "for idx in tqdm.tqdm(range(1000)):\n",
        "  example = dataset[\"train\"][idx]\n",
        "  predicted_label = predict_sentiment(example[\"sentence\"])\n",
        "  if predicted_label == example[\"label\"]:\n",
        "    num_correct += 1\n",
        "print()\n",
        "print(\"Accuracy: {}\".format(num_correct / 1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRSLyI4hWk9F"
      },
      "source": [
        "Our best performing model gets 85% accuracy on this task, and our template-only baseline (i.e., without any training examples in the context) gets 69%. We'll assign full credit to any solutions that score above 70%, but we encourage you to try to beat our scores! Please be aware that prompting can lead to high variance results, and checkout the following paper for additional tips and details: https://arxiv.org/pdf/2102.09690.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocRqxldcNY4k"
      },
      "outputs": [],
      "source": [
        "num_correct = 0\n",
        "predictions = []\n",
        "for example in dataset[\"validation\"]:\n",
        "  predicted_label = predict_sentiment(example[\"sentence\"])\n",
        "  predictions.append(predicted_label)\n",
        "np.save(\"sst_predictions.npy\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTlwnboWigBF"
      },
      "source": [
        "Congratulations! You've now finished the programming components of HW1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJsliV9WiRHB"
      },
      "source": [
        "### Gradescope\n",
        "\n",
        "To download this notebook, go to `File->Download .ipynb`.  Please rename the file to match the name in our file list.  You can download other outputs by clicking the > arrow near the top left and finding it under `Files`. When submitting your ipython notebooks, make sure everything runs correctly if the cells are executed in order starting from a fresh session.  Note that just because a cell runs in your current session doesn't mean it doesn't rely on code that you have already changed or deleted.  If the code doesn't take too long to run, we recommend re-running everything with `Runtime->Restart and run all...`."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "hw1c.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
